# -*- coding: utf-8 -*-
"""probando.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dy-F0Lyw7xq_0imrDPW87UghXESy4-Dm

# **Trabajo Pr치ctico Final: Redes Neuronales Convolucionales en TensorFlow**

# **游늼 Consigna**
Identificar un problema de clasificaci칩n multiclase de imagenes que puedan resolver utilizando una red neuronal convolucional implementada en **Keras** utilizando **TensorFlow** como vimos en clase. Desarrollar un modelo para resolver en un Python Notebook, donde dise침en una red e implementen como adaptar los datos de entrada a una matriz, para pasarla por un modelo creado con Keras. Se pueden apoyar del ejemplo resuelto sobre el dataset de MNIST de clasificaci칩n de Digitos en este Notebook

**Ademas en el mismo notebook deber치n:**
*   Explicar el problema a resolver y la soluci칩n propuesta
*   Identificar y explicar los conceptos te칩ricos vistos en clase sobre modelado y entrenamiento de redes neuronales. Tip: visualizar el modelo con alg칰n paquete como keras-visualizer para explicar su comportamiento.
*   Visualizar los datos de entrada, ejemplos tomados del dataset, y algunos ejemplos de salida.

Se puede optar por resolver el problema con el dataset de Fashion MNIST. Este ya viene cargado en Google Colab. Pueden encontrar otros datasets en Kaggle o directamente de internet.

El problema que buscamos solucionar es la reconocimiento de animales, entre ellos los gatos y perros y animales salvajes. La solucion propuesta es la clasificaci칩n de estas mediante redes neuronales convuncionales.

Este es el link al Dataset de Kaggle
[cats and dogs](https://www.kaggle.com/datasets/samuelcortinhas/cats-and-dogs-image-classification?resource=download&select=test)
"""

!pip install keras-visualizer

import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras.preprocessing import image_dataset_from_directory
from keras_visualizer import visualizer
from tensorflow.keras.utils import plot_model
from PIL import Image
import numpy as np

#importamos todas las librerias que vamos a usar

from google.colab import drive
drive.mount('/content/drive')

#conectamos con el drive

train_dir = '/content/drive/MyDrive/archive (2)/train'
test_dir = '/content/drive/MyDrive/archive (2)/test'

#direcciones de las carpetas test y train del drive

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir, # le doy la direccion de la carpeta
    labels='inferred', # le pone la etiqueta dependiendo de su carpeta
    batch_size=32,
    image_size=(256, 256), #tama침o
    shuffle=True, #para que se mezclen aleatoriamente
    seed=321,
    validation_split=0.2, #cuanto va para la validacion
    subset='training',
)
test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    test_dir,
    labels='inferred',
    batch_size=32,
    image_size=(256, 256),
    shuffle=True,
    seed=321,
    validation_split=0.2,
    subset='validation',
)

#convieto las imagenes que estan dentro de las carpetas a un dataset
#ademas como estos estan dentro de carpetas, le pone el label de la carpeta donde estas

rescale = Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (rescale(x), y))
test_ds = test_ds.map(lambda x, y: (rescale(x), y))

#scalear las fotos

for images, labels in train_ds.take(1):
    print(f"Min value: {np.min(images)}")
    print(f"Max value: {np.max(images)}")
    break

#nos fijamos cual es el scale

"""En un comienzo no habiamos scaleado las imagenes y el accuracy que resibiamos era muy bajo por lo que luego decidimos hacer un resacle"""

model =keras.Sequential() # creo el modelo
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256,256,3))) # aplico filtros para que se noten mas los bordes
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))

#hacemos multiples veces pooling y cnv2d para llegar a un resultado m치s preciso

model.add(Flatten())#Convierte la salida de las capas anteriores en un vector unidimensional.
model.add(Dense(64, activation='relu'))#A침ade una capa densa con 64 neuronas.
model.add(Dense(2))
model.compile(optimizer='adam', #utilizamos el optimizer adam
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_ds, epochs=5,
                    validation_data=(test_ds))

model.add(Flatten())#Convierte la salida de las capas anteriores en un vector unidimensional.
model.add(Dense(64, activation='relu'))#A침ade una capa densa con 64 neuronas.
model.add(Dense(2))
model.compile(optimizer='sgd', # usamos el ultimizer sgd
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_ds, epochs=5,
                    validation_data=(test_ds))

"""previo a agregarle el optimizer Adam, el accuracy nos daba un estumado de 60 y en la mayoria de fotos que luego probabamos al 50% le erraba, por lo que decidimos implementarlo. Tambien probamos con el optimizer sgd ambos dieron resultados parecidos, pero por una leve diferencia, termino siendo mas preciso el Sgd.  """

visualizer(model, file_format='png', view=True)
from PIL import Image
Image.open("graph.png")
#visualizamos el modelo, con la secuencia de Conv2D y MaxPooling2D. Despues se muestran las neuronas. Tenemos 10 relu y 2 outputs de linear activation

plot_model(model, to_file='model.png')
#Aca tenemos los kernels que aplican filtros a la imagen de entrada, cada filtro detecta patrones especificos. Maxpooling2D reduce la dimensi칩n espacial de la imagen al mantener solo los valores m치s altos en una ventana espec칤fica.
#El Flatten se encarga de convertir la salida 2D de las capas convolucionales o de pooling en un vector 1D. Y el dense conecta cada neurona de la capa anterior con todas las neuronas de esta capa.

model.save("modeloChona.h5")

class_names = ["cats", "dogs"]
img_url = "/content/drive/MyDrive/archive (2)/test/cats/cat_140.jpg" #Imagen de dog


img = tf.keras.utils.load_img(
    img_url, target_size=(256, 256)
)

img_array = tf.keras.utils.img_to_array(img) #Convierte la imagen en un array de NumPy, que es el formato que entiende TensorFlow para realizar c치lculos.
img_array = tf.expand_dims(img_array, 0)
img_array = img_array / 255.0


predictions = model.predict(img_array) #Devuelve un array con las probabilidades de cada clase.
predicted_class = np.argmax(predictions[0]) #Si la clase con mayor probabilidad es dogs devolver치 1, si es cats devolver치 0.
score = tf.nn.softmax(predictions[0]) #Convierte las probabilidades en valores normalizados entre 0 y 1, sumando en total 1. Facilita interpretar la probabilidad de cada clase.


print(
    "Esta imagen es m치s probable que sea de un {} con un {:.2f} porciento."
    .format(class_names[np.argmax(score)], 100 * np.max(score)) #Convierte la probabilidad en porcentaje.
)